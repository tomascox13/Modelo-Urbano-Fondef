View(zonas_local_area_analisis)
Zonas_Norma_Temuco = st_transform(Zonas_Norma_Temuco, crs = 32719)
Zonas_Norma_Temuco = st_read(paste0(dir_datos,"/input/IPT/Caso Temuco/IPT_Temuco_PLasCasas_Cajon.shp"), crs = 4326)
Zonas_Norma_Temuco = st_transform(Zonas_Norma_Temuco, crs = 32719)
View(Zonas_Norma_Temuco)
Zonas_Norma_Temuco_inters = Zonas_Norma_Temuco[c("ZONA","CUT","INDIC_DENS_vivha")]
source(knitr::purl("./librerias paths y parametros.Rmd", quiet=TRUE))
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
Parametros_Norma_Temuco = read_excel(paste0(dir_datos,"/input/IPT/Caso Temuco/Parametros Norma Temuco.xlsx"))
Zonas_Norma_Temuco = st_read(paste0(dir_datos,"/input/IPT/Caso Temuco/IPT_Temuco_PLasCasas_Cajon.shp"), crs = 4326)
}
#transforma a crs 32719:
Zonas_Norma_Temuco = st_transform(Zonas_Norma_Temuco, crs = 32719)
#Calcula indicador de densidad:
Parametros_Norma_Temuco <- mutate(Parametros_Norma_Temuco, INDIC_DENS_vivha = ifelse(USO_HABIT == "NO", 0, ifelse(dens_max_vivha > 0, dens_max_vivha,ifelse(!is.na(dens_max_habha), (dens_max_habha / 4),(coef_constr_max * 10000 * 0.7 / 70)))))
# en caso que el indicador sea NA (no se puedo calcular con los parámetros indicados), se le asigna 500. Esto resulta de aplicar a un terreno de 2000 m2 una ocupación de 0.5, y rasante de 70 grados, lo que da un edificio de 10 pisos, con 1.000 m2 por planta, 70% de sup util y unidades de 60 m2 promedio. Esto da 100 unidades, lo que llevado a Há, da 500 unidades:
Parametros_Norma_Temuco$INDIC_DENS_vivha[is.na(Parametros_Norma_Temuco$INDIC_DENS_vivha)] = 500
Zonas_Norma_Temuco = merge(Zonas_Norma_Temuco, Parametros_Norma_Temuco[c("ZONA","CUT","INDIC_DENS_vivha")], by = c( "CUT","ZONA"), all.x = TRUE)
View(Zonas_Norma_Temuco)
Zonas_Norma_Temuco_inters = Zonas_Norma_Temuco[c("ZONA","CUT","INDIC_DENS_vivha")]
Zonas_Norma_Temuco_inters$area_ha = as.numeric(st_area(Zonas_Norma_Temuco_inters) /10000)
View(Zonas_Norma_Temuco_inters)
View(zonas_local_area_analisis)
Zonas_Norma_Temuco_inters = st_intersection(Zonas_Norma_Temuco_inters, zonas_local_area_analisis[c("GEOCODIGO")])
View(Zonas_Norma_Temuco_inters)
Zonas_Norma_Temuco_inters = Zonas_Norma_Temuco[c("ZONA","CUT","INDIC_DENS_vivha")]
Zonas_Norma_Temuco_inters$area_ha_zona = as.numeric(st_area(Zonas_Norma_Temuco_inters) /10000)
Zonas_Norma_Temuco_inters = st_intersection(Zonas_Norma_Temuco_inters, zonas_local_area_analisis[c("GEOCODIGO")])
Zonas_Norma_Temuco_inters$area_ha_frag = st_area(Zonas_Norma_Temuco_inters)
Zonas_Norma_Temuco_inters$area_ha_frag = as.numeric(st_area(Zonas_Norma_Temuco_inters) /10000)
source(knitr::purl("./librerias paths y parametros.Rmd", quiet=TRUE))
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
Parametros_Norma = read_excel(paste0(dir_datos,"/input/IPT/Caso Temuco/Parametros Norma Temuco.xlsx"))
Zonas_Norma = st_read(paste0(dir_datos,"/input/IPT/Caso Temuco/IPT_Temuco_PLasCasas_Cajon.shp"), crs = 4326)
}
#transforma a crs 32719:
Zonas_Norma = st_transform(Zonas_Norma, crs = 32719)
#Calcula indicador de densidad:
Parametros_Norma <- mutate(Parametros_Norma, INDIC_DENS_vivha = ifelse(USO_HABIT == "NO", 0, ifelse(dens_max_vivha > 0, dens_max_vivha,ifelse(!is.na(dens_max_habha), (dens_max_habha / 4),(coef_constr_max * 10000 * 0.7 / 70)))))
# en caso que el indicador sea NA (no se puedo calcular con los parámetros indicados), se le asigna 500. Esto resulta de aplicar a un terreno de 2000 m2 una ocupación de 0.5, y rasante de 70 grados, lo que da un edificio de 10 pisos, con 1.000 m2 por planta, 70% de sup util y unidades de 60 m2 promedio. Esto da 100 unidades, lo que llevado a Há, da 500 unidades:
Parametros_Norma$INDIC_DENS_vivha[is.na(Parametros_Norma$INDIC_DENS_vivha)] = 500
Zonas_Norma = merge(Zonas_Norma, Parametros_Norma[c("ZONA","CUT","INDIC_DENS_vivha")], by = c( "CUT","ZONA"), all.x = TRUE)
#genera sf de zonas normativas con solo
Zonas_Norma_inters = Zonas_Norma[c("ZONA","CUT","INDIC_DENS_vivha")]
Zonas_Norma_inters$area_ha_zona = as.numeric(st_area(Zonas_Norma_inters) /10000)
Zonas_Norma_inters = st_intersection(Zonas_Norma_inters, zonas_local_area_analisis[c("GEOCODIGO")])
Zonas_Norma_inters$area_ha_frag = as.numeric(st_area(Zonas_Norma_inters) /10000)
#calcula cuántas viviendas se permiten en cada fragmento:
Zonas_Norma_inters = mutate(Zonas_Norma_inters, vivs_frag = INDIC_DENS_vivha * area_ha_frag)
View(Zonas_Norma_inters)
#agrega la cantidad de vivs por zona/loc censal:
vivs_perm_zonas = aggregate(vivs_frag ~ GEOCODIGO, Zonas_Norma_inters, sum)
View(vivs_perm_zonas)
names(vivs_perm_zonas) = c("GEOCODIGO","vivs_permitidas")
Zonas_Norma = merge(Zonas_Norma, vivs_perm_zonas, by = "GEOCODIGO", all.x = TRUE)
View(Zonas_Norma)
Zonas_Norma = merge(zonas_local_area_analisis, vivs_perm_zonas, by = "GEOCODIGO", all.x = TRUE)
rm(Zonas_Norma)
zonas_local_area_analisis = merge(zonas_local_area_analisis, vivs_perm_zonas, by = "GEOCODIGO", all.x = TRUE)
View(zonas_local_area_analisis)
zonas_local_area_analisis$vivs_perm_zonas[is.na(zonas_local_area_analisis$vivs_perm_zonas)] = 0
zonas_local_area_analisis$vivs_perm_zonas[is.na(zonas_local_area_analisis$vivs_perm_zonas),] = 0
zonas_local_area_analisis$vivs_perm_zonas[is.na(zonas_local_area_analisis$vivs_perm_zonas)] = 0
zonas_local_area_analisis$vivs_perm_zonas[is.na(zonas_local_area_analisis$vivs_perm_zonas)] <- 0
zonas_local_area_analisis[is.na(zonas_local_area_analisis$vivs_perm_zonas)] = 0
zonas_local_area_analisis[is.na(zonas_local_area_analisis$vivs_perm_zonas),] = 0
View(zonas_local_area_analisis)
zonas_local_area_analisis$vivs_permitidas[is.na(zonas_local_area_analisis$vivs_permitidas)] = 0
saveRDS(zonas_local_area_analisis, paste0(dir_datos, "/output/zonas_local_con_vivs_permtid",p_caso_de_estudio,".RDS"))
write_sf(zonas_local_area_analisis, paste0(dir_datos, "/output/shapes/zonas_local_con_vivs_permtid",p_caso_de_estudio,".shp"))
saveRDS(zonas_local_area_analisis, paste0(dir_datos, "/output/zonas_local_con_vivs_permtid_",p_caso_de_estudio,".RDS"))
write_sf(zonas_local_area_analisis, paste0(dir_datos, "/output/shapes/zonas_local_con_vivs_permtid_",p_caso_de_estudio,".shp"))
zonas_local_area_analisis$area_ha_zona = as.numeric(st_area(zonas_local_area_analisis) /10000)
zonas_local_area_analisis = mutate(zonas_local_area_analisis, vivs_perm_ha = vivs_permitidas / area_ha_zona)
saveRDS(zonas_local_area_analisis, paste0(dir_datos, "/output/zonas_local_con_vivs_permtid_",p_caso_de_estudio,".RDS"))
write_sf(zonas_local_area_analisis, paste0(dir_datos, "/output/shapes/zonas_local_con_vivs_permtid_",p_caso_de_estudio,".shp"))
rm(Parametros_Norma,vivs_perm_zonas,Zonas_Norma,zonas_local_area_analisis,Zonas_Norma_inters)
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
centro = st_read(paste0(dir_datos,"/input/shapes/centro temuco.shp"), crs = 32719)
}
roads = st_read( paste0(dir_datos, "/output/shapes/roads_",p_caso_de_estudio,".shp"))
calcula_dist_x_red = readRDS(paste0(dir_datos, "/output/funcion calculo distancia al mas cercano por la red.RDS"))
tbl_zonas = zonas_local_area_analisis[c("GEOCODIGO")]
#funcion de dist requiere de input en 4326:
origenes = st_transform(st_centroid(zonas_local_area_analisis), crs = 4326)
destinos = st_transform(centro, crs = 4326)
red_vial = st_transform(roads, crs = 4326)
#función requiere un campo de ID:
origenes = mutate(origenes, ID = GEOCODIGO)
destinos = mutate(destinos, ID = 1)
#aplica función de calculo de deistancias al más cercano por la red:
dist_centro = calcula_dist_x_red(origenes, destinos, red_vial)
#agrega distancias a tabla de zonas/loc:
tbl_zonas =  merge(tbl_zonas, dist_centro, by.x = "GEOCODIGO", by.y = "ID", all.x = TRUE)
rm(origenes, destinos,red_vial,dist_centro)
View(tbl_zonas)
roads = st_read( paste0(dir_datos, "/output/shapes/roads_",p_caso_de_estudio,".shp"))
calcula_dist_x_red = readRDS(paste0(dir_datos, "/output/funcion calculo distancia al mas cercano por la red.RDS"))
tbl_zonas = zonas_local_area_analisis[c("GEOCODIGO")]
origenes = st_transform(st_centroid(zonas_local_area_analisis), crs = 4326)
destinos = st_transform(centro, crs = 4326)
red_vial = st_transform(roads, crs = 4326)
#función requiere un campo de ID:
origenes = mutate(origenes, ID = GEOCODIGO)
destinos = mutate(destinos, ID = 1)
#aplica función de calculo de deistancias al más cercano por la red:
dist_centro = calcula_dist_x_red(origenes, destinos, red_vial)
View(dist_centro)
names(dist_centro) = c("dist_centro", "GEOCODIGO" )
#agrega distancias a tabla de zonas/loc:
tbl_zonas =  merge(tbl_zonas, dist_centro, by = "GEOCODIGO", all.x = TRUE)
rm(origenes, destinos,red_vial,dist_centro)
View(tbl_zonas)
roads = st_read( paste0(dir_datos, "/output/shapes/roads_",p_caso_de_estudio,".shp"))
red_vial = st_transform(roads, crs = 4326)
#funcion de dist requiere de input en 4326:
origenes = st_transform(st_centroid(zonas_local_area_analisis), crs = 4326)
destinos = st_transform(centro, crs = 4326)
red_vial = st_transform(roads, crs = 4326)
#función requiere un campo de ID:
origenes = mutate(origenes, ID = GEOCODIGO)
destinos = mutate(destinos, ID = 1)
#aplica función de calculo de deistancias al más cercano por la red:
dist_centro = calcula_dist_x_red(origenes, destinos, red_vial)
names(dist_centro) = c("dist_centro", "GEOCODIGO" )
#agrega distancias a tabla de zonas/loc:
tbl_zonas =  merge(tbl_zonas, dist_centro, by = "GEOCODIGO", all.x = TRUE)
rm(origenes, destinos,red_vial,dist_centro)
View(roads)
View(tbl_zonas)
tbl_zonas$dist_centro = tbl_zonas$dist_centro.y
tbl_zonas$dist_centro.y = NULL
tbl_zonas$dist_centro.x = NULL
#tabla con norma por zona/loc censal (precalculada en modulo de normativa):
norma_zonaloc = readRDS(paste0(dir_datos, "/output/zonas_local_con_vivs_permtid_",p_caso_de_estudio,".RDS"))
View(zonas_local_area_analisis)
View(norma_zonaloc)
tbl_zonas = merge(tbl_zonas, norma_zonaloc[c("GEOCODIGO","vivs_permitidas"), by="GEOCODIGO",all.x = TRUE]
tbl_zonas = merge(tbl_zonas, norma_zonaloc[c("GEOCODIGO","vivs_permitidas"), by="GEOCODIGO",all.x = TRUE)
tbl_zonas = merge(tbl_zonas, norma_zonaloc[c("GEOCODIGO","vivs_permitidas")], by="GEOCODIGO",all.x = TRUE)
tbl_zonas = merge(tbl_zonas, st_drop_geometry(norma_zonaloc[c("GEOCODIGO","vivs_permitidas")]), by="GEOCODIGO",all.x = TRUE)
saveRDS(tbl_zonas, paste0(dir_datos, "/output/tabla_atribs_zonasloc",p_caso_de_estudio,".RDS"))
rm(centro, norma_zonaloc,roads, tbl_zonas,zonas_local_area_analisis)
rm(centro, norma_zonaloc,roads, tbl_zonas,zonas_local_area_analisis, calcula_dist_x_red())
rm(centro, norma_zonaloc,roads, tbl_zonas,zonas_local_area_analisis, calcula_dist_x_red)
#tabla de unidades por zona censal:
tabla_unids_zona = readRDS(paste0(dir_datos, "/output/tabla_unids_zona",p_caso_de_estudio,".RDS"))
View(tabla_unids_zona)
tbl_atributos_zonas = readRDS(paste0(dir_datos, "/output/tabla_atribs_zonasloc",p_caso_de_estudio,".RDS"))
View(tbl_atributos_zonas)
tabla_calibracion_modelo = merge(tbl_atributos_zonas,tabla_unids_zona, by = "GEOCODIGO", all.x = TRUE)
tabla_calibracion_modelo$casa[is.na(tabla_calibracion_modelo$casa)] = 0
tabla_calibracion_modelo$departamento[is.na(tabla_calibracion_modelo$departamento)] = 0
tabla_calibracion_modelo$otros[is.na(tabla_calibracion_modelo$otros)] = 0
tabla_calibracion_modelo$otro[is.na(tabla_calibracion_modelo$otro)] = 0
View(tabla_calibracion_modelo)
names(tabla_calibracion_modelo)
linear = lm(casa ~ dist_centr + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm("casa" ~ "dist_centr" + "vivs_permitidas", data = tabla_calibracion_modelo)
linear = lm(casa ~ dist_centr + vivs_permitidas, data = st_drop_geometry(tabla_calibracion_modelo))
library(caret)
linear = lm(casa ~ dist_centr + vivs_permitidas, data = st_drop_geometry(tabla_calibracion_modelo))
tabla_calibracion_modelo = st_drop_geometry(tabla_calibracion_modelo)
tabla_calibracion_modelo =
linear = lm(casa ~ dist_centr + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm(casa ~ dist_centr + vivs_permitidas, data = tabla_calibracion_modelo)
View(tabla_calibracion_modelo)
linear = lm(casa ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
summary(linear)
linear = lm(departamento ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm(departamento ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
summary(linear)
linear = lm(log(departamento) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm(ln(departamento) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm(log(departamento) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
linear = lm(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
summary(linear)
fecha_calibracion = Sys.Date()
modelo_lineal = lm(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
saveRDS(modelo_lineal, paste0(dir_datos, "/output/modelo_lineal_",p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
saveRDS(modelo_lineal, paste0(dir_datos, "/output/modelo_lineal_oferta",p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
saveRDS(modelo_lineal, paste0(dir_datos, "/output/modelo_lineal_oferta_",p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
tabla_ajuste_modelo = tabla_calibracion_modelo [c("departamento","casa")]
tabla_ajuste_modelo$pred_depto = exp(predict(modelo_lineal,tabla_calibracion_modelo))
View(tabla_ajuste_modelo)
ggplot()+
geom_point(tabla_ajuste_modelo, aes(x = departamento, y = pred_depto))
ggplot(tabla_ajuste_modelo)+
geom_point( aes(x = departamento, y = pred_depto))
summary(modelo_lineal)
#tabla con predicciones:
tabla_ajuste_modelo = tabla_calibracion_modelo [c()]
# error medio:
MAPE = mean(abs(tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs))
#tabla con predicciones:
tabla_ajuste_modelo = tabla_calibracion_modelo[c()]
tabla_ajuste_modelo$obs = tabla_calibracion_modelo$departamento
tabla_ajuste_modelo$pred = exp(predict(modelo_lineal,tabla_calibracion_modelo))
# r2:
r2 = cor(tabla_ajuste_modelo$pred,tabla_ajuste_modelo$obs)^2
summary(modelo_lineal)
# r2:
r2 = cor(tabla_ajuste_modelo$pred,tabla_ajuste_modelo$obs)^2
# error medio:
MAPE = mean(abs(tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs))
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)/ tabla_ajuste_modelo$obs))
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)/ tabla_ajuste_modelo$obs+0.001))
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)/ tabla_ajuste_modelo$obs+0.001))
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)/ tabla_ajuste_modelo$obs+1))
# error medio:
#tabla_ajuste_modelo = mutate(tabla_ajuste_modelo, errorporc =)
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)/ (tabla_ajuste_modelo$obs+1)))
# error medio:
#tabla_ajuste_modelo = mutate(tabla_ajuste_modelo, errorporc =)
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)*100/ (tabla_ajuste_modelo$obs+1)))
names(modelo_lineal_oferta)
names(modelo_lineal)
names(modelo_lineal$model)
c1 = c("r2", r2)
c2 = c("MAPE", MAPE)
df_ajuste = data.frame(c1,c2)
View(df_ajuste)
df_ajuste = data.frame(r2,MAPE)
View(df_ajuste)
rm(c1,c2)
write.csv(df_ajuste, paste0(dir_datos, "/output/metricas_ajuste_"modelo_a_guardar,p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
write.csv(df_ajuste, paste0(dir_datos, "/output/metricas_ajuste_",modelo_a_guardar,p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
modelo_a_guardar = "modelo_lineal_oferta_"
write.csv(df_ajuste, paste0(dir_datos, "/output/metricas_ajuste_",modelo_a_guardar,p_caso_de_estudio,"_",fecha_calibracion,".RDS"))
write.csv(df_ajuste, paste0(dir_datos, "/output/metricas_ajuste_",modelo_a_guardar,p_caso_de_estudio,"_",fecha_calibracion,".csv"))
write.csv(df_ajuste, paste0(dir_datos, "/output/metricas_ajuste_",modelo_a_guardar,p_caso_de_estudio,"_",fecha_calibracion,".csv"),row.names = FALSE)
modelo_rf_oferta = rf(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
modelo_rf_oferta <- randomForest(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo, trControl = control)
control <- trainControl(method='repeatedcv',
number=10,
repeats=10)
modelo_rf_oferta <- randomForest(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo, trControl = control)
library(randomForest)
modelo_rf_oferta <- randomForest(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo, trControl = control)
modelo = modelo_rf_oferta
#tabla con predicciones:
tabla_ajuste_modelo = tabla_calibracion_modelo[c()]
tabla_ajuste_modelo$obs = tabla_calibracion_modelo$departamento
modelo = modelo_lineal_oferta
modelo_lineal_oferta = lm(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
summary(modelo_lineal)
#modelo = modelo_lineal_oferta
modelo = modelo_rf_oferta
#tabla con predicciones:
tabla_ajuste_modelo = tabla_calibracion_modelo[c()]
tabla_ajuste_modelo$obs = tabla_calibracion_modelo$departamento
tabla_ajuste_modelo$pred = exp(predict(modelo,tabla_calibracion_modelo)) # ojo exp
# r2:
r2 = cor(tabla_ajuste_modelo$pred,tabla_ajuste_modelo$obs)^2
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)*100/ (tabla_ajuste_modelo$obs+1)))
df_ajuste = data.frame(r2,MAPE)
ggplot(tabla_ajuste_modelo)+
geom_point( aes(x = departamento, y = pred_depto))
ggplot(tabla_ajuste_modelo)+
geom_point( aes(x = obs, y = pred))
#modelo = modelo_lineal_oferta
#tabla_est = tabla_calibracion_modelo
modelo = modelo_rf_oferta
tabla_est = valid
sample = sample.split(tabla_calibracion_modelo$GEOCODIGO, SplitRatio = 0.8)
library(caTools)
sample = sample.split(tabla_calibracion_modelo$GEOCODIGO, SplitRatio = 0.8)
train = subset(tabla_calibracion_modelo, sample == TRUE)
valid = subset(tabla_calibracion_modelo, sample == FALSE)
control <- trainControl(method='repeatedcv',
number=10,
repeats=10)
modelo_rf_oferta <- randomForest(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = train, trControl = control)
#modelo = modelo_lineal_oferta
#tabla_est = tabla_calibracion_modelo
modelo = modelo_rf_oferta
tabla_est = valid
tabla_ajuste_modelo = tabla_est[c()]
tabla_ajuste_modelo = tabla_est[c()]
tabla_ajuste_modelo$obs = tabla_est$departamento
tabla_ajuste_modelo$pred = exp(predict(modelo,tabla_est))
# r2:
r2 = cor(tabla_ajuste_modelo$pred,tabla_ajuste_modelo$obs)^2
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)*100/ (tabla_ajuste_modelo$obs+1)))
df_ajuste = data.frame(r2,MAPE)
ggplot(tabla_ajuste_modelo)+
geom_point( aes(x = obs, y = pred))
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal, modelo_rf, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona)
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal, modelo_rf, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona, r2, MAPE, sample)
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal_oferta, modelo_rf_oferta, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona, r2, MAPE, sample, modelo_a_guardar)
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal_oferta, modelo_rf_oferta, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona, r2, MAPE, sample, modelo_a_guardar, tabla_est)
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal_oferta, modelo_rf_oferta, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona, r2, MAPE, sample, modelo_a_guardar, tabla_est, tbl_atributos_zonas)
rm(control, train, valid, tabla_unids_zona, df_ajuste, linear, modelo, modelo_lineal_oferta, modelo_rf_oferta, tabla_ajuste_modelo, tabla_calibracion_modelo, tabla_unids_zona, r2, MAPE, sample, modelo_a_guardar, tabla_est, tbl_atributos_zonas, fecha_calibracion)
source(knitr::purl("./librerias paths y parametros.Rmd", quiet=TRUE))
#para cargar todos los datos del censo (no alcanza la memoria), filtra por región 9 y guarda como RDS:
Microdato_Censo2017_Personas = read.csv("C:/Users/tomas/OneDrive/Censo2017/Microdato_Censo2017-Personas/Microdato_Censo2017-Personas.csv",sep = ";")
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
}
#carga datos solo de la Región (ya filtrados anteriormente):
if(p_caso_de_estudio == "Temuco"){
Microdato_Censo2017_Personas_Region = readRDS(paste0(dir_datos, "/output/Microdato_Censo2017_Personas_Araucania.RDS"))
}
# genera geocodigo de cada persona
Microdato_Censo2017_Personas_Region = mutate(Microdato_Censo2017_Personas_Region, GEOCOD = as.numeric(paste0(COMUNA,ifelse(DC <= 9,paste0("0",DC),DC),ifelse(AREA == 1, 1000 + ZC_LOC, 2000 + ZC_LOC))))
# filtra solo las personas en las zonas y localidades del área de estudio:
geocods_zonasylocs_area_estudio = zonas_local_area_analisis$GEOCODIGO
Microdato_Censo2017_Personas_AreaEstudio =  Microdato_Censo2017_Personas_Region [Microdato_Censo2017_Personas_Region$GEOCOD %in% geocods_zonasylocs_area_estudio,]
rm(Microdato_Censo2017_Personas_Region)
#filtra por la(s) comuna(s) del área de análisis (ya no se usa, se usa el anterior):
#cod_comunas = p_cod_comunas$Comuna
#Microdato_Censo2017_Personas_Comunas =  Microdato_Censo2017_Personas_Region [Microdato_Censo2017_Personas_Region$COMUNA %in% cod_comunas,]
#rm(Microdato_Censo2017_Personas_Region)
#guarda tabla de todas las personas de las comunas del area de estudio:
saveRDS(Microdato_Censo2017_Personas_AreaEstudio, paste0(dir_datos, "/output/Microdato_Censo2017_Personas_", p_caso_de_estudio,".RDS"))
# genera ID de hogar:
Microdato_Censo2017_Personas_AreaEstudio = mutate(Microdato_Censo2017_Personas_AreaEstudio, ID_HOG = paste0(GEOCOD,"-",NVIV,"-",NHOGAR))
#hace tabla de hogares con ID de hogar:
tabla_hogares = as.data.frame(unique(Microdato_Censo2017_Personas_AreaEstudio$ID_HOG))
names(tabla_hogares) = c("ID_HOG")
#edades maxima y minima en cada hogar:
edad_max = aggregate(P09 ~ ID_HOG, Microdato_Censo2017_Personas_AreaEstudio, max)
edad_min = aggregate(P09 ~ ID_HOG, Microdato_Censo2017_Personas_AreaEstudio, min)
names(edad_max) = c("ID_HOG","edad_max_hog")
names(edad_min) = c("ID_HOG","edad_min_hog")
#nivel educacional del jefe de hogar:
jefe_hog = subset(Microdato_Censo2017_Personas_AreaEstudio, P07 == 1)
jefe_hog = jefe_hog[c("ID_HOG","ESCOLARIDAD")]
#geocodigo:
geoc = aggregate(GEOCOD ~ ID_HOG, Microdato_Censo2017_Personas_AreaEstudio, mean)
#agrega a tabla de hogares:
tabla_hogares = merge(tabla_hogares, jefe_hog, by = "ID_HOG", all.x = TRUE)
tabla_hogares = merge(tabla_hogares, edad_max, by = "ID_HOG", all.x = TRUE)
tabla_hogares = merge(tabla_hogares, edad_min, by = "ID_HOG", all.x = TRUE)
tabla_hogares = merge(tabla_hogares, geoc, by = "ID_HOG", all.x = TRUE)
rm(edad_max,edad_min,geoc,jefe_hog)
#ciclo de vida:
tabla_hogares = mutate(tabla_hogares, segm_edad = ifelse(edad_min_hog >=18 & edad_max_hog < 65, "indep",ifelse(edad_min_hog < 18 & edad_max_hog < 65, "cninos", "admayor" )))
#educacional:
tabla_hogares = mutate(tabla_hogares, segm_educ = ifelse(ESCOLARIDAD == 99 | ESCOLARIDAD <= 8, "basica", ifelse( ESCOLARIDAD <=12, "media", ifelse(ESCOLARIDAD < 17, "sup_incomp", "sup_comp"))))
#segmentacion:
tabla_hogares = mutate(tabla_hogares, segmento = paste0(segm_edad,"-",segm_educ))
#resumen:
resumen_segmentos_hog = aggregate(ID_HOG ~ segmento, subset(tabla_hogares,!is.na(ESCOLARIDAD)), length)
View(tabla_hogares)
View(resumen_segmentos_hog)
View(resumen_segmentos_hog)
write.csv(resumen_segmentos_hog, paste0(dir_datos, "/output/resumen_segmentos_hog",p_caso_de_estudio,".RDS"))
write.csv(resumen_segmentos_hog, paste0(dir_datos, "/output/resumen_segmentos_hog",p_caso_de_estudio,".ccsv"))
write.csv(resumen_segmentos_hog, paste0(dir_datos, "/output/resumen_segmentos_hog",p_caso_de_estudio,".csv"))
write.csv(resumen_segmentos_hog, paste0(dir_datos, "/output/resumen_segmentos_hog_",p_caso_de_estudio,".csv"), row.names = FALSE)
View(zonas_local_area_analisis)
a = merge(zonas_local_area_analisis, tabla_hogares, by = "GEOCODIGO", all.x = TRUE)
View(tabla_hogares)
hogs_zonas = aggregate(ID_HOG ~ GEOCOD + segmento, tabla_hogares)
hogs_zonas = aggregate(ID_HOG ~ GEOCOD + segmento, tabla_hogares, length)
View(hogs_zonas)
View(hogs_zonas)
a = dcast(hogs_zonas, GEOCOD ~ segmento, value.var = "ID_HOG"))
a = dcast(hogs_zonas, GEOCOD ~ segmento, value.var = "ID_HOG")
View(a)
View(hogs_zonas)
View(tabla_hogares)
tabla_hogares = subset(tabla_hogares, !is.na(tabla_hogares))
tabla_hogares = subset(tabla_hogares, !is.na(ESCOLARIDAD))
hogs_zonas = aggregate(ID_HOG ~ GEOCOD + segmento, tabla_hogares, length)
a = dcast(hogs_zonas, GEOCOD ~ segmento, value.var = "ID_HOG")
hogs_zonas = dcast(hogs_zonas, GEOCOD ~ segmento, value.var = "ID_HOG")
a = merge(zonas_local_area_analisis, hogs_zonas, by = "GEOCODIGO", all.x = TRUE)
a = merge(zonas_local_area_analisis, hogs_zonas,by.x = "GEOCODIGO", by.y = "GEOCOD", all.x = TRUE)
View(a)
zonas_local_area_analisis = merge(zonas_local_area_analisis, hogs_zonas,by.x = "GEOCODIGO", by.y = "GEOCOD", all.x = TRUE)
st_write(zonas_local_area_analisis, paste0(dir_datos, "/output/shapes/segmentos_hog_",p_caso_de_estudio,".shp"))
saveRDS(tabla_hogares, paste0(dir_datos, "/output/tabla_hogares",p_caso_de_estudio,".RDS"))
write.csv(resumen_segmentos_hog, paste0(dir_datos, "/output/resumen_segmentos_hog_",p_caso_de_estudio,".csv"), row.names = FALSE)
rm(tabla_hogares, resumen_segmentos_hog, Microdato_Censo2017_Personas_AreaEstudio, zonas_local_area_analisis,geocods_zonasylocs_area_estudio)
rm(a)
rm(tabla_hogares, resumen_segmentos_hog, Microdato_Censo2017_Personas_AreaEstudio, zonas_local_area_analisis,geocods_zonasylocs_area_estudio, hogs_zonas)
tipologias_2002_2017 = read_excel(paste0(dir_datos,"/input/PH Tipología_de_vivienda_por_region_y_comuna_Censo_2017_2002.xlsx"))
cod_comunas = p_cod_comunas$Comuna
tipologias_2002_2017_comunas =  tipologias_2002_2017 [tipologias_2002_2017$`Codigo INE Comuna` %in% cod_comunas,]
#calcula otros = los que no son ni depto ni casa:
tipologias_2002_2017_comunas = mutate(tipologias_2002_2017_comunas, otros =  `Piezas en casa antigua o conventillo` + `Mediagua, mejora, Rancho o Choza` + `Vivienda Tradicional Indígena (ruka, pae pae u otras)` + `Móvil (carpa, casa rodante o similar)` + `Otro tipo de vivienda particular`)
# resumen por censo y sector (urb, rural), para cada tipo:
resumen_tipologias = aggregate(Casa ~ Año + Area, tipologias_2002_2017_comunas, sum )
res_deptos = aggregate(`Departamento en edificio` ~ Año + Area, tipologias_2002_2017_comunas, sum )
res_otros = aggregate(otros ~ Año + Area, tipologias_2002_2017_comunas, sum )
resumen_tipologias = merge(resumen_tipologias,res_deptos, by = c("Año","Area"), all.x = TRUE)
resumen_tipologias = merge(resumen_tipologias,res_otros, by = c("Año","Area"), all.x = TRUE)
resumen_tipologias = mutate(resumen_tipologias, total = Casa + `Departamento en edificio` + otros)
#porcentajes:
resumen_tipologias = mutate(resumen_tipologias, porc_Casas = Casa * 100 / total)
resumen_tipologias = mutate(resumen_tipologias, porc_Deptos = `Departamento en edificio` * 100 / total)
resumen_tipologias = mutate(resumen_tipologias, porc_Otros = otros * 100 / total)
rm(res_deptos, res_otros)
View(resumen_tipologias)
write.csv(resumen_tipologias, paste0(dir_datos, "/output/resumen_tipologias",p_caso_de_estudio,".csv"), row.names = FALSE)
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
}
#cantidad por año:
View(aggregate(CANTIDAD_U ~ AÑO, permisos_area_estudio, sum))
# por destino:
View(aggregate(CANTIDAD_U ~ USO_DESTIN, permisos_area_estudio, sum))
# por destino especifico:
View(aggregate(CANTIDAD_U ~ GLOSA_DEST, permisos_area_estudio, sum))
permisos_2010_21_nacional = st_read("C:/Users/tomas/OneDrive/Shapes/permisos de edificacion ine/georreferenciados/permisos_edificacion_2010_2021 wgs84_19s.shp", crs = 32719)
permisos_area_estudio = st_intersection(permisos_2010_21_nacional, zonas_local_area_analisis)
rm(permisos_2010_21_nacional)
#renombra algunas variables:
colnames(permisos_area_estudio)[which(names(permisos_area_estudio) == "A.d1.O")] <- "AÑO"
#cantidad por año:
View(aggregate(CANTIDAD_U ~ AÑO, permisos_area_estudio, sum))
# por destino:
View(aggregate(CANTIDAD_U ~ USO_DESTIN, permisos_area_estudio, sum))
# por destino especifico:
View(aggregate(CANTIDAD_U ~ GLOSA_DEST, permisos_area_estudio, sum))
rm(Parametros_Norma,vivs_perm_zonas,zonas_local_area_analisis,Zonas_Norma_inters)
rm(permisos_area_estudio, tabla_unids_zona, zonas_local_area_analisis,shp_unids_zonas)
rm(tipologias_2002_2017, tipologias_2002_2017_comunas, resumen_tipologias)
source(knitr::purl("./librerias paths y parametros.Rmd", quiet=TRUE))
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
Parametros_Norma = read_excel(paste0(dir_datos,"/input/IPT/Caso Temuco/Parametros Norma Temuco.xlsx"))
Zonas_Norma = st_read(paste0(dir_datos,"/input/IPT/Caso Temuco/IPT_Temuco_PLasCasas_Cajon.shp"), crs = 4326)
}
#para caso de Temuco:
if(p_caso_de_estudio == "Temuco"){
zonas_local_area_analisis = st_read(paste0(dir_datos,"/input/shapes/shapes censo 2017 Araucania/area_estudio_temuco.shp"), crs = 32719)
Parametros_Norma = read_excel(paste0(dir_datos,"/input/IPT/Caso Temuco/Parametros Norma Temuco.xlsx"))
Zonas_Norma = st_read(paste0(dir_datos,"/input/IPT/Caso Temuco/IPT_Temuco_PLasCasas_Cajon.shp"), crs = 4326)
}
#transforma a crs 32719:
Zonas_Norma = st_transform(Zonas_Norma, crs = 32719)
tbl_zonas = readRDS(paste0(dir_datos, "/output/tabla_atribs_zonasloc",p_caso_de_estudio,".RDS"))
View(tbl_zonas)
st_write(tbl_zonas, paste0(dir_datos, "/output/shapes/atribs_zonasloc",p_caso_de_estudio,".shp"))
5*0.5+6*0.25+6*0.25
5.5 * (4/7)
#tabla de unidades por zona censal:
tabla_unids_zona = readRDS(paste0(dir_datos, "/output/tabla_unids_zona",p_caso_de_estudio,".RDS"))
#atributos por zona censal (todas las zonas):
tbl_atributos_zonas = readRDS(paste0(dir_datos, "/output/tabla_atribs_zonasloc",p_caso_de_estudio,".RDS"))
rm(centro, norma_zonaloc,roads, tbl_zonas,zonas_local_area_analisis, calcula_dist_x_red)
#tabla de unidades por zona censal:
tabla_unids_zona = readRDS(paste0(dir_datos, "/output/tabla_unids_zona",p_caso_de_estudio,".RDS"))
#atributos por zona censal (todas las zonas):
tbl_atributos_zonas = readRDS(paste0(dir_datos, "/output/tabla_atribs_zonasloc",p_caso_de_estudio,".RDS"))
tabla_calibracion_modelo = merge(tbl_atributos_zonas,tabla_unids_zona, by = "GEOCODIGO", all.x = TRUE)
tabla_calibracion_modelo$casa[is.na(tabla_calibracion_modelo$casa)] = 0
tabla_calibracion_modelo$departamento[is.na(tabla_calibracion_modelo$departamento)] = 0
tabla_calibracion_modelo$otro[is.na(tabla_calibracion_modelo$otro)] = 0
tabla_calibracion_modelo = st_drop_geometry(tabla_calibracion_modelo)
modelo_lineal_oferta = lm(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = tabla_calibracion_modelo)
summary(modelo_lineal)
summary(modelo_lineal_oferta)
sample = sample.split(tabla_calibracion_modelo$GEOCODIGO, SplitRatio = 0.8)
train = subset(tabla_calibracion_modelo, sample == TRUE)
valid = subset(tabla_calibracion_modelo, sample == FALSE)
control <- trainControl(method='repeatedcv',
number=10,
repeats=10)
modelo_rf_oferta <- randomForest(log(departamento + 0.001) ~ dist_centro + vivs_permitidas, data = train, trControl = control)
#modelo = modelo_lineal_oferta
#tabla_est = tabla_calibracion_modelo
modelo = modelo_rf_oferta
tabla_est = valid
#tabla con predicciones:
tabla_ajuste_modelo = tabla_est[c()]
tabla_ajuste_modelo$obs = tabla_est$departamento
tabla_ajuste_modelo$pred = exp(predict(modelo,tabla_est)) # ojo exp
# r2:
r2 = cor(tabla_ajuste_modelo$pred,tabla_ajuste_modelo$obs)^2
# error medio:
MAPE = mean(abs((tabla_ajuste_modelo$pred -  tabla_ajuste_modelo$obs)*100/ (tabla_ajuste_modelo$obs+1)))
df_ajuste = data.frame(r2,MAPE)
ggplot(tabla_ajuste_modelo)+
geom_point( aes(x = obs, y = pred))
codigos_comunas_ine = read.csv("../input/codigos_comunas_ine.csv",sep=";")
codigos_comunas_ine = read.csv("../dato/input/codigos_comunas_ine.csv",sep=";")
codigos_comunas_ine = read.csv("../datos/input/codigos_comunas_ine.csv",sep=";")
proyecciones_2002_2035 = read_excel("../datos/input/estimaciones-y-proyecciones-2002-2035-comuna-y-área-urbana-y-rural.xlsx")
library(caret)
library(caTools)
library(dplyr)
library(dodgr)
library(ggplot2)
#library(mapedit)
#library(leaflet)
library(osmdata)
library(randomForest)
library(readxl)
library(reshape2)
library(sf)
#library(tidyr)
#library(caret)
proyecciones_2002_2035 = read_excel("../datos/input/estimaciones-y-proyecciones-2002-2035-comuna-y-área-urbana-y-rural.xlsx")
